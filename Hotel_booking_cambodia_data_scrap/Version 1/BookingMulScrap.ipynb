{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the needed library\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30 hotels. \n",
      "There are 30 hotels. \n",
      "There are 30 hotels. \n",
      "There are 30 hotels. \n",
      "There are 30 hotels. \n",
      "There are 30 hotels. \n",
      "There are 30 hotels. \n",
      "There are 30 hotels. \n",
      "There are 30 hotels. \n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "for i in range(0,201,25):\n",
    "    header = {\n",
    "    'user-agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Mobile Safari/537.36',\n",
    "    'referer' : f'https://www.booking.com/searchresults.en-gb.html?aid=306395&label=siemreab-kJBeG0FmtAToFiFqh*J72gS525624659477:pl:ta:p1700:p2:ac:ap:neg:fi:tiaud-146342136310:kwd-108164414:lp1009829:li:dec:dm:ppccp=UmFuZG9tSVYkc2RlIyh9YZVcNNsENnH02-pWD53qm9c&sid=3c523558a1c1dc70c2d8efa4237ca8d2&checkin=2023-04-14&checkout=2023-04-15&city=-1032755&offset={i}'\n",
    "    }\n",
    "    url = f'https://www.booking.com/searchresults.en-gb.html?label=siemreab-kJBeG0FmtAToFiFqh*J72gS525624659477%3Apl%3Ata%3Ap1700%3Ap2%3Aac%3Aap%3Aneg%3Afi%3Atiaud-146342136310%3Akwd-108164414%3Alp1009829%3Ali%3Adec%3Adm%3Appccp%3DUmFuZG9tSVYkc2RlIyh9YZVcNNsENnH02-pWD53qm9c&sid=3c523558a1c1dc70c2d8efa4237ca8d2&aid=306395&checkin=2023-04-14&checkout=2023-04-15&city=-1032755&offset={i}'\n",
    "\n",
    "    # request to scrap data---- 200 = ok to\n",
    "    html_text = requests.get(url=url, headers=header)\n",
    "    html_text.status_code\n",
    "\n",
    "    # 'lxml' : is a parser(a feature or tool for scraping )\n",
    "    bsoup = soup(html_text.text, 'lxml')\n",
    "\n",
    "    # Scrapping for all hotel\n",
    "    hotel = []\n",
    "    hotelFind = bsoup.findAll('div', {'data-testid': 'property-card'})\n",
    "    for name in hotelFind:\n",
    "        hotel.append(name.text.strip().split(','))\n",
    "    print(f'There are {len(hotel)} hotels. ')\n",
    "\n",
    "    #scrapping for hotel Name\n",
    "    hotelName = []\n",
    "    nameFind = bsoup.find_all(\"h2\")\n",
    "    for name in nameFind:\n",
    "        hotelName.append(name.text.strip())\n",
    "    hotelName = hotelName[:-1]\n",
    "\n",
    "    # scrapping for review count for each hotel\n",
    "    reviews = []\n",
    "    noReviews = []\n",
    "    test = []\n",
    "    hotelReview = bsoup.findAll('div', {'data-testid':'review-score'})\n",
    "    for review in hotelReview:\n",
    "        reviews.append(review.text.strip()[:3])\n",
    "        noReviews.append(review.text.replace(\"·\", \"\").replace('reviews', '').strip()[-4:])\n",
    "        test.append(review.text.strip())\n",
    "\n",
    "    # scraping for prices\n",
    "    pricesHotel = []\n",
    "    hotelPrice = bsoup.findAll('span', {'data-testid':'price-and-discounted-price'})\n",
    "    for price in hotelPrice:\n",
    "        pricesHotel.append(price.text.replace('KHR', '').strip())\n",
    "        \n",
    "    # Scraping for Location\n",
    "    location = []\n",
    "    locFind = bsoup.findAll('div', {'data-testid': 'location'})\n",
    "    for loc in locFind:\n",
    "        location.append(loc.text.replace(\"•\", \"|\").strip())\n",
    "        \n",
    "    # Scraping for URL\n",
    "    href = []\n",
    "    for i in bsoup.find_all(\"a\"):\n",
    "        href.append(i.attrs['href'])\n",
    "    href = href[2:32]\n",
    "\n",
    "    #Add to dictionary\n",
    "    d1 = {'Hotel':hotelName, 'Price':pricesHotel, 'Location' : location, 'Url': href}\n",
    "\n",
    "    # Add to dataframe\n",
    "    df = pd.DataFrame.from_dict(d1)\n",
    "\n",
    "    # Make csv file\n",
    "    fileName = df.to_csv(f'BookingScrap{k}.csv')\n",
    "    k+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "os.chdir(\"C:/Users/Acer/Downloads/I3/Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "#export to csv\n",
    "combined_csv.to_csv( \"combinedBooking.csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
